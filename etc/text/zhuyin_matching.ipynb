{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69bf903-6351-472f-964f-c36d41c3ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019dc34e-8b40-49b9-9155-1f8188071eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../../data\")\n",
    "if not data_dir.exists():\n",
    "    data_dir = Path(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70795df-1e87-479b-80c3-b66723f0f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_data = json.load((data_dir/Path(\"李昆澤-127844.gasr.json\")).open(encoding=\"UTF-8\"))\n",
    "metadata = json.load((data_dir/Path(\"metadata.json\")).open(encoding=\"UTF-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98dca26-b023-4f52-9ff6-e7ee45826a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr = asr_data[\"response\"][\"results\"]\n",
    "transcript = [x for x in metadata if x[\"video_id\"]==\"127844\"][0][\"transcript\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ccd5a83-743f-4fc2-8adb-00e28d66d1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = (data_dir/Path(\"李昆澤-127844.turn.ans.txt\")).read_text().split(\",\")\n",
    "len(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dab374",
   "metadata": {},
   "source": [
    "## 轉注音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b54e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypinyin\n",
    "import re\n",
    "from pypinyin import lazy_pinyin, Style\n",
    "from difflib import SequenceMatcher\n",
    "from functools import cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7abf7233",
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_re = re.compile(\"[ˊˇˋ˙]\")\n",
    "\n",
    "@cache\n",
    "def pinyin_cache(ch):\n",
    "    return lazy_pinyin(ch, style=Style.BOPOMOFO)[0]\n",
    "\n",
    "class CharPhone:\n",
    "    def __init__(self, ch):\n",
    "        assert len(ch)==1\n",
    "        self.ch = ch\n",
    "        self.zhuyin = pinyin_cache(ch)\n",
    "        self.phones = tone_re.sub(\"\", self.zhuyin)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.phones)\n",
    "    \n",
    "    def __eq__(self, other):        \n",
    "        return self.phones == other.phones\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<Char: {self.ch} ({self.zhuyin})>\"        \n",
    "\n",
    "def char_mapper(text):\n",
    "    text = re.sub(\"[ \\u3000，。：）（]\", \"\", text)\n",
    "    return [CharPhone(x) for x in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cfd9b64-1762-438d-abb8-08ff286bcc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SequenceMatcher(lambda x: not x.ch in \"（）\", char_mapper(\"中視（新聞\"), char_mapper(\"中式）心文\")).ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ccb40d-ad70-4f6c-a88a-41f313b0f94f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21c1f021-0e6f-4dc1-a2ae-51dd2e0bba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def to_num(x):\n",
    "    return float(x.replace(\"s\", \"\"))\n",
    "\n",
    "def flatten_asr(asr_obj):    \n",
    "    asr_starts = []\n",
    "    asr_ends = []\n",
    "    asr_words = []\n",
    "    for entry_x in asr_obj:\n",
    "        alts = entry_x.get(\"alternatives\", [])\n",
    "        if not alts: continue\n",
    "        words = alts[0].get(\"words\", [])        \n",
    "        asr_starts.extend([\n",
    "            to_num(x[\"startTime\"]) for x in words])\n",
    "        asr_ends.extend([\n",
    "            to_num(x[\"endTime\"]) for x in words])\n",
    "        asr_words.extend([x[\"word\"] for x in words])\n",
    "        \n",
    "    return {\n",
    "        \"starts\": asr_starts,\n",
    "        \"ends\": asr_ends,\n",
    "        \"words\": asr_words\n",
    "    }\n",
    "\n",
    "flat_asr = flatten_asr(asr)\n",
    "assert len(flat_asr[\"starts\"]) == len(flat_asr[\"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53a378e5-7efd-49d0-a56b-d7b96b1a23f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alternatives': [{'confidence': 0.8894143,\n",
       "   'transcript': '謝謝主席，請夏林佳龍部長還很有錢人，家人不算機業局長有沒有局長？',\n",
       "   'words': [{'endTime': '6s', 'startTime': '1.300s', 'word': '謝'},\n",
       "    {'endTime': '6.100s', 'startTime': '6s', 'word': '謝'},\n",
       "    {'endTime': '6.300s', 'startTime': '6.100s', 'word': '主'},\n",
       "    {'endTime': '6.500s', 'startTime': '6.300s', 'word': '席'},\n",
       "    {'endTime': '6.800s', 'startTime': '6.500s', 'word': '請'},\n",
       "    {'endTime': '7.100s', 'startTime': '6.800s', 'word': '夏'},\n",
       "    {'endTime': '7.400s', 'startTime': '7.100s', 'word': '林'},\n",
       "    {'endTime': '7.600s', 'startTime': '7.400s', 'word': '佳'},\n",
       "    {'endTime': '7.600s', 'startTime': '7.600s', 'word': '龍'},\n",
       "    {'endTime': '7.800s', 'startTime': '7.600s', 'word': '部'},\n",
       "    {'endTime': '7.900s', 'startTime': '7.800s', 'word': '長'},\n",
       "    {'endTime': '8.400s', 'startTime': '7.900s', 'word': '還'},\n",
       "    {'endTime': '8.700s', 'startTime': '8.400s', 'word': '很'},\n",
       "    {'endTime': '8.800s', 'startTime': '8.700s', 'word': '有'},\n",
       "    {'endTime': '9s', 'startTime': '8.800s', 'word': '錢'},\n",
       "    {'endTime': '9.200s', 'startTime': '9s', 'word': '人'},\n",
       "    {'endTime': '9.300s', 'startTime': '9.200s', 'word': '家'},\n",
       "    {'endTime': '9.400s', 'startTime': '9.300s', 'word': '人'},\n",
       "    {'endTime': '9.600s', 'startTime': '9.400s', 'word': '不'},\n",
       "    {'endTime': '9.700s', 'startTime': '9.600s', 'word': '算'},\n",
       "    {'endTime': '10s', 'startTime': '9.700s', 'word': '機'},\n",
       "    {'endTime': '10.700s', 'startTime': '10s', 'word': '業'},\n",
       "    {'endTime': '10.900s', 'startTime': '10.700s', 'word': '局'},\n",
       "    {'endTime': '11.100s', 'startTime': '10.900s', 'word': '長'},\n",
       "    {'endTime': '12.300s', 'startTime': '11.100s', 'word': '有'},\n",
       "    {'endTime': '12.400s', 'startTime': '12.300s', 'word': '沒'},\n",
       "    {'endTime': '12.500s', 'startTime': '12.400s', 'word': '有'},\n",
       "    {'endTime': '12.700s', 'startTime': '12.500s', 'word': '局'},\n",
       "    {'endTime': '12.900s', 'startTime': '12.700s', 'word': '長'}]}],\n",
       " 'languageCode': 'cmn-hant-tw',\n",
       " 'resultEndTime': '13.450s'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95474414-4925-4915-8e49-0d7081d687ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 議事錄逐字稿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a12ad282-7872-41cb-843e-970ab4603cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import tee\n",
    "def preprocess_transcript(txt):\n",
    "    txt = txt.replace(\"<br />\", \"\")\n",
    "    txt = re.split(\"(\\n?.+?：)\", txt)    \n",
    "    txt = [x.replace(\"\\n\", \"\").strip() for x in txt]\n",
    "    txt = [x for x in txt if x]\n",
    "    iter_list = [iter(txt)] * 2\n",
    "    turns = [(a,b) for a,b in zip(*iter_list)]\n",
    "    turns = [x for x in turns if not x[0].startswith(\"主席：\")]\n",
    "    return turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "338ba680-3e6e-4535-bc78-d770761e790f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('李委員昆澤：',\n",
       "  '（10 時 13 分）部長，您好。遊艇證照弊案傷害政府的威信，也影響到考照的公平性，更是衝擊到航運的安全，這一次的事件整體來看，內部監理出了重大漏洞，這個部分請部長簡單說明一下。'),\n",
       " ('林部長佳龍：',\n",
       "  '不管原因是什麼，我們要阻止類似的事情再發生，所以我在第一時間得知檢調在偵辦，就要求同仁同步清查並全面提供資料，而且要澈底建立防弊的措施，不管是相關的作業程序或者承辦人的職權，整個檢討跟改進。'),\n",
       " ('李委員昆澤：',\n",
       "  '航港局的檢討報告提到，要限縮相關人員的權限，加強勾稽比對，並由科長來核對、覆核，系統要更新，限制成績須整批匯入，發照人員也要定期輪調。我也具體的建議，我們必須要加強內部稽核和不定期查核，請簡單說明。')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turns = preprocess_transcript(transcript)\n",
    "turns[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3b9ae-ff4c-4a78-8985-c73a5c077297",
   "metadata": {},
   "source": [
    "## 兩邊對齊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415b12c5",
   "metadata": {},
   "source": [
    "### 用注音對齊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71afd306-b925-48c3-83d6-8ec49fefc510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9947114eff4d2599e2f287472c7817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "win = 20\n",
    "offset = 1\n",
    "asr_words = flat_asr[\"words\"] \n",
    "asr_starts = flat_asr[\"starts\"]\n",
    "asr_ends = flat_asr[\"ends\"]\n",
    "\n",
    "aligned_turn_start = []\n",
    "current_idx = 0\n",
    "for turn_x in tqdm(turns):\n",
    "    probe = turn_x[1][offset:offset+win]    \n",
    "\n",
    "    scores = []\n",
    "    for i in range(len(asr_words)-win):                \n",
    "        target = \"\".join(asr_words[i:i+win]) \n",
    "        sm = SequenceMatcher(None,\n",
    "                char_mapper(probe), char_mapper(target))\n",
    "        scores.append(sm.ratio())\n",
    "    \n",
    "    scores = np.array(scores)\n",
    "    scores[:max(current_idx, 2)] = -1\n",
    "    align_idx = np.argmax(scores)\n",
    "    current_idx = max(align_idx, current_idx)\n",
    "    # print(f\"[{max(scores)}]\")\n",
    "    # print(\"Probe:\", probe)\n",
    "    # print(\"Target: \", \"\".join(asr_words[align_idx:align_idx+win]))\n",
    "    aligned_turn_start.append(asr_starts[align_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a5fdf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers aligned\n",
      "00:00:15 00:00:09 5.7\n",
      "00:00:40 00:00:42 -2.8\n",
      "00:01:14 00:01:19 -5.2\n",
      "00:01:42 00:01:43 -1.1\n",
      "00:02:41 00:02:41 -0.2\n",
      "00:03:54 00:03:56 -2.1\n",
      "00:04:09 00:04:10 -1.9\n",
      "00:04:33 00:04:33 -0.8\n",
      "00:06:36 00:06:36 -0.3\n",
      "00:07:01 00:07:00 0.3\n",
      "00:08:24 00:08:24 -0.7\n",
      "00:08:39 00:08:24 14.3\n",
      "00:08:39 00:08:40 -1.1\n",
      "00:10:05 00:10:06 -1.2\n",
      "00:10:46 00:10:46 -0.6\n",
      "00:11:09 00:11:09 -0.3\n",
      "00:11:32 00:11:27 4.8\n",
      "00:11:33 00:11:32 0.3\n",
      "00:11:54 00:11:52 1.3\n",
      "00:11:56 00:11:53 3.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "print(\"answers\", \"aligned\")\n",
    "dt = lambda x: x.strftime(\"%H:%M:%S\")\n",
    "for i in range(len(turns)):\n",
    "    ans_dt = datetime.strptime(ans[i], \"%H:%M:%S\")\n",
    "    aligned_dt = datetime(1900,1,1)+timedelta(seconds=aligned_turn_start[i])    \n",
    "    print(dt(ans_dt), dt(aligned_dt), (ans_dt-aligned_dt).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8754c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric(aligned, ans, tol=3.):\n",
    "    assert len(aligned) == len(ans)\n",
    "    n_correct = 0\n",
    "\n",
    "    for aligned_x, ans_x in zip(aligned, ans):\n",
    "        t = datetime.strptime(ans_x,\"%H:%M:%S\")\n",
    "        ansTD = timedelta(hours=t.hour, minutes=t.minute, seconds=t.second).total_seconds()\n",
    "        alignTD = timedelta(seconds=aligned_x).total_seconds()\n",
    "\n",
    "        error = abs(ansTD-alignTD)\n",
    "\n",
    "        if error < tol:\n",
    "            n_correct += 1\n",
    "    metric = n_correct/len(aligned)\n",
    "    return metric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1ce457fa-b118-406a-8853-496d413a6182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metric(aligned_turn_start, ans, tol=5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a05618df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0:09:23] 李委員昆澤： （10 時 13 分）部長，您好。遊艇證照弊案傷害政府的威信，也影響到考照的公平性，更是衝擊到航運的安全，這一次的事件整體來看，內部監理出了重大漏洞，這個部分請部長簡單說明一下。\n",
      "[0:00:42] 林部長佳龍： 不管原因是什麼，我們要阻止類似的事情再發生，所以我在第一時間得知檢調在偵辦，就要求同仁同步清查並全面提供資料，而且要澈底建立防弊的措施，不管是相關的作業程序或者承辦人的職權，整個檢討跟改進。\n",
      "[0:01:19] 李委員昆澤： 航港局的檢討報告提到，要限縮相關人員的權限，加強勾稽比對，並由科長來核對、覆核，系統要更新，限制成績須整批匯入，發照人員也要定期輪調。我也具體的建議，我們必須要加強內部稽核和不定期查核，請簡單說明。\n",
      "[0:01:42] 葉局長協隆： 謝謝委員，目前我們已經全面變更並改正系統的設定，還有受理申辦的流程，現在承辦人是沒有辦法做任何資料的更改，在發證前，系統也設定成績必須要合格才能夠發證，在考駕照的控管上，也由科長來控管空白駕照以及流水號，每天都必須要逐日核對，並按月做成紀錄往上呈報並做覆核。另外委員剛剛提醒的，要做實地和外部的稽核部分，我們去年 10 月和去年 12 月已經做了兩次到中部航務中心的外部稽核，今年 6 月和 7 月也分別會針對六大項目來進行進一步的實地查核。\n",
      "[0:02:41] 李委員昆澤： 好，這個部分，剛才很多委員提到相關的題庫艱深，而且大部分都是船機的相關知識，我們應該強化考照的流程，另外針對題庫的合理性以及相關的適用性，必須提出更具體的檢討和改進，而且航行的安全教育真的是非常重要，也必須要加強。我現在要請教的是針對貨櫃的數量，航港局有沒有掌握？現在因為疫情的影響，全世界的海運快速發展，大家需求的貨櫃數量都大幅增加，甚至有錢可能也買不到貨櫃，相關的狀況，我們看到臺灣是一個重要的進出口國家，海運是我們重要的經濟支柱，相對的，海運如果缺乏貨櫃的話，恐怕對經濟會造成重大的影響，這部分請局長簡單說明一下。\n",
      "[0:03:55] 葉局長協隆： 跟委員報告，全球海運缺櫃的現象是受到新冠肺炎疫情的影響，造成港口塞港以致貨櫃的回流速度減緩，造成整個缺櫃的情形。\n",
      "[0:04:10] 李委員昆澤： 局長，我們針對缺櫃這樣一個嚴重的狀況，有沒有具體的改善重點？甚至我們有沒有成立協調的工作小組去盤點相關的廠商出口的需求？對於空櫃的回流是不是有具體的掌握？請具體說明。\n",
      "[0:04:33] 葉局長協隆： 跟委員報告，去年 10 月部長就提醒我們有這樣的現象，我們經過檢討之後，在去年12 月已經成立一個國際海運的平穩小組，除了航港局之外，並由經濟部工業局、國貿局及農委會、港務公司來組成，我們採取的措施總共有五大部分，第一個就是剛剛委員提到的，我們每10 天到兩個禮拜主動調查進出口業者貨櫃的需求，如果有無法滿足的部分，我們會主動協調國籍航商來提供增加船班和艙位以滿足需求。我用幾個數字跟委員很快報告一下，第一，我們在 1 月初調查第一次的時候，需要的家數有97 家有貨櫃無法滿足的情形，數量是 1 萬 5,000 個，在經過第二次這樣的協調機制之後，在 1月底已經降到 32 家 230 個貨櫃；到 2 月底的時候，只剩下 9 家有貨櫃無法滿足的情形，需求的貨櫃是 53 個；到 3 月底的數字是 30 家 79 個貨櫃無法滿足，整個貨櫃的提供率大概是八成左右，如果沒有辦法滿足 100 個貨櫃，我們透過協調能夠提供 80 個貨櫃，另外還有 20 個貨櫃沒有辦法滿足的部分，最主要是買方和賣方因為運價的考量暫時沒有辦法達成協議，針對這個部分，我們也建議雙方在現有商業協調機制，可以透過運費的協議，讓貨櫃的出口更順暢。\n",
      "[0:06:36] 李委員昆澤： 部長，這個非常重要，因為我們在 1 月的時候整體的出口增加 30%以上，尤其在第三季更是進出口一個重要的旺季，相關的貨櫃數量也影響到我們臺灣整體出口的產業經濟發展，部長有沒有掌握相關貨櫃數量的狀況？\n",
      "[0:07:01] 林部長佳龍： 有，現在大概不缺櫃而是價格的問題，至於供需，我主持過會議，我們召集 4 家國籍航商及業者、公協會坐下來談，所以除了一個資訊平臺，大概把過年前塞櫃問題解決得差不多，將近有兩萬 TEU，現在針對今年可能的缺櫃，我們也超前部署，一家一家調查，目前總共有46 艘新船會進來，大概有 33 萬 TEU 可以來提供我們的國貨由國人來運。當然，在商言商，過去我們的國籍航商也不一定優先以國內的需求為主，導致價格惡性競爭，事實上是虧損，所以這個時候我們利用這個危機希望建立一個平臺，在符合公平交易和世界貿易組織的規範下，我們當然可以鼓勵簽一些長約，讓國內這些很重要的產業有國籍航商可以先運；另外一點，對於外籍航商能夠靠港，我們也提供一些優惠，所以到目前來講，今年度開始，雖然貨櫃的價格還是高，但是供需大概是可以滿足國內產業的需求。\n",
      "[0:08:24] 李委員昆澤： 部長必須要清楚掌握這些艙位以及貨櫃數量，因為這的確是影響臺灣的海運以及整體出口的相關產業經濟之整體發展，而且剛才我也提醒你，第三季旺季馬上就要到了。\n",
      "[0:00:01] 林部長佳龍： 對。\n",
      "[0:04:08] 李委員昆澤： 現在我要請教葉局長，有關於郵輪觀光的發展，不管是跳島或是環島，郵輪在高雄的發展成效都必須要加強，因為我在 2020 年 12 月 28 日質詢時，航港局表示 2020 年 12 月 27 日到 2021 年 4 月 5 日，跳島和環島航程預計有 42 航次，而且航港局已經安排 21 航次停靠高雄港，加上該等航次中，會有 6 個航次是由高雄港出發，聽起來很開心，但是實際上到 2021 年 3 月11 日為止，總共是 46 航次，其中 21 個航次是去年 12 月 28 日之前，而且實際航次只有 25 個航次而已，所以 2020 年 12 月到 2021 年 4 月總共有 8 個航次停靠高雄港而已，但是原始預估到 4月 5 日應該要到達 21 個航次，「說的嚇死人、做的笑死人」，差很多耶！局長的宣示跟實際上的效果差很多，你來說明一下。\n",
      "[0:10:06] 葉局長協隆： 跟委員報告，這個部分的確跟原來預估有一個落差，我們瞭解最主要是年初的時候受到海氣象影響，還有載客率和訂位的情況不甚理想等原因，有取消部分的航班，這個部分我們會主動來協調郵輪業者跟港務公司，透過這些優惠的措施來鼓勵業者停靠高雄，目前有相關新的郵輪業者來跟我們接洽，這個部分我們都會鼓勵高雄這邊，不管是母港或掛靠港，多從高雄這邊來出發。\n",
      "[0:01:15] 李委員昆澤： 部長、局長，航港局必須跟港務公司、業者、地方政府密切合作，你要提供優質有特色的相關服務，而且針對相關停靠的費用，我們是否給予優待跟減免以吸引更多業者到高雄？這個部分說明一下。\n",
      "[0:11:09] 林部長佳龍： 我跟委員說明，其實為什麼 1 月那時候會降下來，除了剛剛局長講的，還有疫情，那一陣子因為部桃的關係，所以我們事實上是很謹慎，因為郵輪可能萬一有一些群聚的感染，這是非常嚴重的。所以寧可……\n",
      "[0:11:29] 李委員昆澤： 這部分可以理解。\n",
      "[0:11:32] 林部長佳龍： 現在疫苗也研發了，再考量各方的情況，所以我們也啟動新一輪遊輪跳島的許可。現在全世界很多的郵輪業都想申請來臺灣，我們很謹慎，現在有 3 大 1 小在申請中。高雄港的部分，我們認為條件非常好。\n",
      "[0:11:54] 李委員昆澤： 請部長全力督促，繼續加油！\n",
      "[0:11:54] 林部長佳龍： 我們一定會全力來辦理，謝謝。\n"
     ]
    }
   ],
   "source": [
    "for start_time, (speaker, transcript) in zip(aligned_turn_start, turns):\n",
    "    timestamp = str(timedelta(seconds=start_time)).split(\".\")[0]\n",
    "    print(\"[{}] {} {}\".format(timestamp, speaker, transcript))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cc34c",
   "metadata": {},
   "source": [
    "### 用字對齊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41681d5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9371718c4b549a7b2fbd2b79e91b8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ch_win = 10\n",
    "ch_offset = 2\n",
    "asr_words = flat_asr[\"words\"] \n",
    "asr_starts = flat_asr[\"starts\"]\n",
    "is_punct = lambda x: x in \"，。：）（\"\n",
    "\n",
    "ch_aligned_turn_start = []\n",
    "current_idx = 0\n",
    "for turn_x in tqdm(turns):\n",
    "    probe = turn_x[1][ch_offset:ch_offset+ch_win]\n",
    "\n",
    "    scores = []\n",
    "    for i in range(len(asr_words)-ch_win):                \n",
    "        target = \"\".join(asr_words[i:i+ch_win]) \n",
    "        sm = SequenceMatcher(is_punct,\n",
    "                probe, target)\n",
    "        scores.append(sm.ratio())\n",
    "\n",
    "    scores = np.array(scores)\n",
    "    scores[:max(current_idx, 2)] = -1\n",
    "    align_idx = np.argmax(scores)\n",
    "    current_idx = max(align_idx, current_idx)\n",
    "    \n",
    "    # print(f\"[{max(scores)}]\")\n",
    "    # print(\"Probe:\", probe)\n",
    "    # print(\"Target: \", \"\".join(asr_words[align_idx:align_idx+20]))\n",
    "    ch_aligned_turn_start.append(asr_starts[align_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5904b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers aligned\n",
      "00:00:15 00:00:09 5.7\n",
      "00:00:40 00:00:42 -2.8\n",
      "00:01:14 00:01:19 -5.2\n",
      "00:01:42 00:01:43 -1.1\n",
      "00:02:41 00:02:41 -0.2\n",
      "00:03:54 00:03:56 -2.1\n",
      "00:04:09 00:04:10 -1.9\n",
      "00:04:33 00:04:33 -0.8\n",
      "00:06:36 00:06:36 -0.3\n",
      "00:07:01 00:07:00 0.3\n",
      "00:08:24 00:08:24 -0.7\n",
      "00:08:39 00:08:24 14.3\n",
      "00:08:39 00:08:40 -1.1\n",
      "00:10:05 00:10:06 -1.2\n",
      "00:10:46 00:10:46 -0.6\n",
      "00:11:09 00:11:09 -0.3\n",
      "00:11:32 00:11:27 4.8\n",
      "00:11:33 00:11:32 0.3\n",
      "00:11:54 00:11:52 1.3\n",
      "00:11:56 00:11:53 3.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "print(\"answers\", \"aligned\")\n",
    "dt = lambda x: x.strftime(\"%H:%M:%S\")\n",
    "for i in range(len(turns)):\n",
    "    ans_dt = datetime.strptime(ans[i], \"%H:%M:%S\")\n",
    "    aligned_dt = datetime(1900,1,1)+timedelta(seconds=aligned_turn_start[i])    \n",
    "    print(dt(ans_dt), dt(aligned_dt), (ans_dt-aligned_dt).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3c649ad3-c990-46ed-b7c2-d9c2436b0bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metric(ch_aligned_turn_start, ans, tol=5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d122d554-7026-4fb8-8848-dee43e997574",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "      {\"timestamp\": 10.2, \"speaker\": \"\", \"transcript\": \"\"},\n",
    "    {\"timestamp\": 10.2, \"speaker\": \"\", \"transcript\": \"\"},\n",
    "    {\"timestamp\": 10.2, \"speaker\": \"\", \"transcript\": \"\"},\n",
    "    {\"timestamp\": 10.2, \"speaker\": \"\", \"transcript\": \"\"},\n",
    "    ...    \n",
    "]\n",
    "\n",
    "import json\n",
    "with open(\"\") as fout:\n",
    "    json.dump(data,fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
